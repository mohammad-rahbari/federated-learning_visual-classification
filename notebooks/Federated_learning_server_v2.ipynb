{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-rahbari/federated-learning_visual-classification/blob/mmd_branch/notebooks/Federated_learning_server_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and data"
      ],
      "metadata": {
        "id": "QH6umXWdxe2I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ve754mVLEmoO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wpogmY-iMNWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4dafc9-bfe9-4707-8857-8161c5be4334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F83IfINuLwqq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c317774-7a35-4913-d513-f83b54021b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:12<00:00, 13.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title In this block we import the test set of CIFAR100 to evaluate the global model\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting data of models we want to aggregate"
      ],
      "metadata": {
        "id": "Illl7SphzfXZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "AhE739SgMX_4",
        "outputId": "770a8f3d-df8d-4665-b219-371a5cf9a8f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3636830833.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Client's log file has been loaded in this block so we can use it in next steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclients_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclients_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv'"
          ]
        }
      ],
      "source": [
        "#@title Client's log file has been loaded in this block so we can use it in next steps\n",
        "clients_data = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\")\n",
        "clients_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bbp5dn-EBcgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQB4dFXLUIp7"
      },
      "outputs": [],
      "source": [
        "initial_model_name = \"db569e2d-3e81-4b69-bc11-a708fd499ca7\" #@param{\"type\":\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "lhoHGiZVUDgo",
        "outputId": "100464f1-440e-4fcb-d9cd-f667c724ab48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of all trained clients: 1\n",
            "Number of clients after filtering: 1\n",
            "Contributors: ['4413e8c9-56df-475c-b6ab-cf4da68d8f31']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   client_id     backbone                            model_name  \\\n",
              "0          0  dino_vits16  4413e8c9-56df-475c-b6ab-cf4da68d8f31   \n",
              "\n",
              "                     initial_model_name  \\\n",
              "0  db569e2d-3e81-4b69-bc11-a708fd499ca7   \n",
              "\n",
              "                                                path  num_of_clients  \\\n",
              "0  /content/drive/MyDrive/MLDL_FederatedLearning/...              20   \n",
              "\n",
              "       Measurement_criteria   accuracy      loss  train_loss  ...  \\\n",
              "0  accuracy,loss,train_loss  98.349633  0.172851    0.214547  ...   \n",
              "\n",
              "  size_of_dataset  client_train_size  client_test_size  \\\n",
              "0           50000               1636               410   \n",
              "\n",
              "              train_test_ratio  classes  round_number   duration  \\\n",
              "0  {'train': 0.8, 'test': 0.2}      all             1  68.489718   \n",
              "\n",
              "                  time                                    path_to_subsets  \\\n",
              "0  2025-06-10 23:21:13  /content/drive/MyDrive/MLDL_FederatedLearning/...   \n",
              "\n",
              "   path_to_class_combs  \n",
              "0                  NaN  \n",
              "\n",
              "[1 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9290b4c5-3785-41c3-86a6-1d14685eb78b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>backbone</th>\n",
              "      <th>model_name</th>\n",
              "      <th>initial_model_name</th>\n",
              "      <th>path</th>\n",
              "      <th>num_of_clients</th>\n",
              "      <th>Measurement_criteria</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>...</th>\n",
              "      <th>size_of_dataset</th>\n",
              "      <th>client_train_size</th>\n",
              "      <th>client_test_size</th>\n",
              "      <th>train_test_ratio</th>\n",
              "      <th>classes</th>\n",
              "      <th>round_number</th>\n",
              "      <th>duration</th>\n",
              "      <th>time</th>\n",
              "      <th>path_to_subsets</th>\n",
              "      <th>path_to_class_combs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>4413e8c9-56df-475c-b6ab-cf4da68d8f31</td>\n",
              "      <td>db569e2d-3e81-4b69-bc11-a708fd499ca7</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>20</td>\n",
              "      <td>accuracy,loss,train_loss</td>\n",
              "      <td>98.349633</td>\n",
              "      <td>0.172851</td>\n",
              "      <td>0.214547</td>\n",
              "      <td>...</td>\n",
              "      <td>50000</td>\n",
              "      <td>1636</td>\n",
              "      <td>410</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>1</td>\n",
              "      <td>68.489718</td>\n",
              "      <td>2025-06-10 23:21:13</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9290b4c5-3785-41c3-86a6-1d14685eb78b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9290b4c5-3785-41c3-86a6-1d14685eb78b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9290b4c5-3785-41c3-86a6-1d14685eb78b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_clients_data"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "filter =  clients_data['initial_model_name']== initial_model_name\n",
        "filtered_clients_data = clients_data[filter] # Using filter to collect clients with specified initial model\n",
        "params = filtered_clients_data[['backbone',\n",
        "                                    'num_of_clients',\n",
        "                                    'splitting_method',\n",
        "                                    'size_of_dataset']]\n",
        "params = dict(params.iloc[0])\n",
        "print(\"Number of all trained clients:\", len(clients_data))\n",
        "print(\"Number of clients after filtering:\", len(filtered_clients_data))\n",
        "contributors = [] # contributors is being used to store the name of models which contributes in aggregation\n",
        "for i  in filtered_clients_data['model_name'].values:\n",
        "  contributors.append(i)\n",
        "print(\"Contributors:\", contributors)\n",
        "filtered_clients_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j78bLPfZmAU"
      },
      "outputs": [],
      "source": [
        "#@title Dino Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DinoClassifire(nn.Module):\n",
        "  def __init__(self, dino_model, num_classes:int=100, device=None):\n",
        "    super(DinoClassifier, self).__init__()\n",
        "    self.backbone = dino_model\n",
        "\n",
        "    #We need to freaze thhe parameters of bakbone first so we can train only on the head layer(output layer)\n",
        "    for param in self.backbone.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    #determine the Device\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.backbone.to(device)\n",
        "\n",
        "    #To detect the output feature dimontion of backbone we run  Dummy forward pass\n",
        "    with torch.no_grad():\n",
        "\n",
        "      dummy_input = torch.randn(1,3,224,224).to(device)\n",
        "      dummy_out = self.backbone(dummy_input)\n",
        "\n",
        "\n",
        "      if isinstance(dummy_out, tuple):\n",
        "        dummy_out = dummy_out[0]\n",
        "      elif isinstance(dummy_out, dict):\n",
        "        dummy_out = dummy_out.get(\"x_norm_clstoken\", next(iter(dummy_out.values())))\n",
        "\n",
        "      #If the output is 3D (B, T, D), we assume first token is the [CLS] token.\n",
        "      if dummy_out.dim() == 3:\n",
        "        dummy_feature = dummy_out[:,0]\n",
        "      else:\n",
        "        dummy_feature = dummy_out\n",
        "      feature_dim = dummy_feature.shape[1]\n",
        "      print(\"Detected feature dimontion:\", feature_dim)\n",
        "\n",
        "\n",
        "      #Hidden Layer\n",
        "      self.hidden = nn.Sequential(\n",
        "          nn.Linear(feature_dim, 128),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "\n",
        "      #Difineing the classification Head\n",
        "      self.head = nn.Linear(128, num_classes)\n",
        "\n",
        "      #Ensure the head is trainable.\n",
        "      for param in self.hidden.parameters():\n",
        "        param.requires_grad = True\n",
        "      for param in self.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #pass the input through the backbone\n",
        "    features = self.backbone(x)\n",
        "\n",
        "    if isinstance(features, tuple):\n",
        "      features = features[0]\n",
        "    elif isinstance(features, dict):\n",
        "      features = features.get(\"x_norm_clstoken\", next(iter(features.values())))\n",
        "\n",
        "\n",
        "    # If featers are retuened as (B, T, D), use the first token\n",
        "    if features.dim() == 3:\n",
        "      features = features[:,0]\n",
        "\n",
        "\n",
        "    hidden_out  = self.hidden(features)\n",
        "\n",
        "    logits = self.head(hidden_out)\n",
        "\n",
        "    return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDoFGHyOXo-K"
      },
      "outputs": [],
      "source": [
        "# @title `get_model` function retrieves and loads the models of filtered clients\n",
        "def get_model(paths,sample_sizes, backbone):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = DinoClassifire(backbone=backbone, num_classes=100, device=device) # Loading an initial custom dino model\n",
        "  for index in range(len(paths)):\n",
        "    state_dict = torch.load(paths.iloc[index]) # load state dict regarding the client number 'index'\n",
        "    model.head.load_state_dict(state_dict[\"head\"]) # set the state dict based on client\n",
        "    model.hidden.load_state_dict(state_dict[\"hidden\"]) # set the state dict based on client\n",
        "\n",
        "    model.to(device)\n",
        "    yield (model,sample_sizes.iloc[index]) # this command throws model one at the time so less time and resouces will be used"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregation functions\n",
        "\n",
        "Implemented algorithm:\n",
        "\n",
        "*   FebAvg\n",
        "*   FebAvgM\n",
        "*   EMA\n",
        "\n"
      ],
      "metadata": {
        "id": "bqUWwoTVBcgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <h2>FebAvg</h2>\n",
        "def feb_avg(df):\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if global_weights[\"head\"] is None:\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        global_model = copy.deepcopy(model)\n",
        "        for k in global_weights[\"head\"].keys():\n",
        "          global_weights[\"head\"][k].zero_() # This command sets the tensor to zero\n",
        "        for k in global_weights[\"hidden\"].keys():\n",
        "          global_weights[\"hidden\"][k].zero_() # This command sets the tensor to zero\n",
        "\n",
        "      for k in global_weights[\"head\"].keys():\n",
        "        global_weights[\"head\"][k] += model.head.state_dict()[k] * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "      for k in global_weights[\"hidden\"].keys():\n",
        "        global_weights[\"hidden\"][k] += model.hidden.state_dict()[k] * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "    global_model.head.load_state_dict(global_weights[\"head\"]) # A model with modified head will be assignd\n",
        "    global_model.hidden.load_state_dict(global_weights[\"hidden\"]) # A model with modified hidden will be assignd\n",
        "  return global_model\n",
        "\n"
      ],
      "metadata": {
        "id": "1wDV2Y3-OKlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FebAvgM\n",
        "def feb_avg_m(df, momentum_coefficient=0.9, momentum_vector_path= None):\n",
        "\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  delta = {\"head\":None, \"hidden\":None} # `delta` is variable that keep the average of clients\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if delta['head'] is None:\n",
        "\n",
        "        global_model = copy.deepcopy(model)\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        delta[\"head\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"head\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "        delta[\"hidden\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"hidden\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "\n",
        "\n",
        "      client_head = model.head.state_dict()\n",
        "      for k in delta['head'].keys():\n",
        "        delta['head'][k] += (client_head[k] - global_weights[\"head\"][k]) * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "\n",
        "      client_hidden = model.hidden.state_dict()\n",
        "      for k in delta['hidden'].keys():\n",
        "        delta['hidden'][k] += (client_hidden[k] - global_weights[\"hidden\"][k]) * (sample_size / total_samples) # Each weight\n",
        "\n",
        "    # In this section we calculate the momentum_vector\n",
        "\n",
        "\n",
        "    if momentum_vector_path is None:\n",
        "      momentum_vector = {\n",
        "          \"head\": {k: delta[\"head\"][k].clone() for k in delta[\"head\"]},\n",
        "          \"hidden\": {k: delta[\"hidden\"][k].clone() for k in delta[\"hidden\"]}\n",
        "      }\n",
        "    else:\n",
        "      momentum_vector = torch.load(momentum_vector_path) #In rounds > 1 momentum vector is requerd to be loaded from drive\n",
        "      for k in delta['head'].keys():\n",
        "        momentum_vector['head'][k] = momentum_coefficient * momentum_vector['head'][k]  + delta['head'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "      for k in delta['hidden'].keys():\n",
        "        momentum_vector['hidden'][k] = momentum_coefficient * momentum_vector['hidden'][k]  + delta['hidden'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    global_head = copy.deepcopy(global_model.head.state_dict())\n",
        "    for k in momentum_vector['head'].keys():\n",
        "      global_head[k] =global_head[k] + momentum_vector['head'][k] #After adding momentum vector the last global model we use clamp function we insure to keep momentum vector in boundary\n",
        "    global_hidden = copy.deepcopy(global_model.hidden.state_dict())\n",
        "    for k in momentum_vector['hidden'].keys():\n",
        "      global_hidden[k] = global_hidden[k] + momentum_vector['hidden'][k]#After adding momentum vector the last global model we use clamp function\n",
        "\n",
        "\n",
        "    global_model.head.load_state_dict(global_head)\n",
        "    global_model.hidden.load_state_dict(global_hidden)\n",
        "\n",
        "\n",
        "  return global_model, momentum_vector # We return momentum_vector to save it and use for next aggregation steps\n",
        "\n"
      ],
      "metadata": {
        "id": "sNxSyQmpOMFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title EMA\n",
        "def EMA(df, decay=0.9, momentum_vector_path= None):\n",
        "\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  delta = {\"head\":None, \"hidden\":None} # `delta` is variable that keep the average of clients\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if delta['head'] is None:\n",
        "\n",
        "        global_model = copy.deepcopy(model)\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        delta[\"head\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"head\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "        delta[\"hidden\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"hidden\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "\n",
        "\n",
        "      client_head = model.head.state_dict()\n",
        "      for k in delta['head'].keys():\n",
        "        delta['head'][k] += (client_head[k] - global_weights[\"head\"][k]) * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "\n",
        "      client_hidden = model.hidden.state_dict()\n",
        "      for k in delta['hidden'].keys():\n",
        "        delta['hidden'][k] += (client_hidden[k] - global_weights[\"hidden\"][k]) * (sample_size / total_samples) # Each weight\n",
        "\n",
        "    # In this section we calculate the momentum_vector\n",
        "\n",
        "\n",
        "    if momentum_vector_path is None:\n",
        "      momentum_vector = {\n",
        "          \"head\": {k: delta[\"head\"][k].clone() for k in delta[\"head\"]},\n",
        "          \"hidden\": {k: delta[\"hidden\"][k].clone() for k in delta[\"hidden\"]}\n",
        "      }\n",
        "    else:\n",
        "      momentum_vector = torch.load(momentum_vector_path) #In rounds > 1 momentum vector is requerd to be loaded from drive\n",
        "      for k in delta['head'].keys():\n",
        "\n",
        "        momentum_vector['head'][k] = decay * momentum_vector['head'][k]  + (1- decay) *  delta['head'][k]  # Using the the formula of EMA we calculate the momentum vector\n",
        "      for k in delta['hidden'].keys():\n",
        "        momentum_vector['hidden'][k] = decay * momentum_vector['hidden'][k]  + (1- decay) *  delta['hidden'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    global_head = copy.deepcopy(global_model.head.state_dict())\n",
        "    for k in momentum_vector['head'].keys():\n",
        "      global_head[k] =global_head[k] + momentum_vector['head'][k] #After adding momentum vector the last global model we use clamp function we insure to keep momentum vector in boundary\n",
        "    global_hidden = copy.deepcopy(global_model.hidden.state_dict())\n",
        "    for k in momentum_vector['hidden'].keys():\n",
        "      global_hidden[k] = global_hidden[k] + momentum_vector['hidden'][k]#After adding momentum vector the last global model we use clamp function\n",
        "\n",
        "\n",
        "    global_model.head.load_state_dict(global_head)\n",
        "    global_model.hidden.load_state_dict(global_hidden)\n",
        "\n",
        "\n",
        "  return global_model, momentum_vector # We return momentum_vector to save it and use for next aggregation steps\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyQ9s1udbhJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTG0_BCipHwT"
      },
      "outputs": [],
      "source": [
        "# @title This function will evaluate the model.</br> The outputs are loss and accuracy\n",
        "def evaluation(model, data_loader):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  test_loss = 0\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in  data_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, prediction = torch.max(outputs.data,1)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item() * labels.size(0)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (prediction == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    loss = test_loss / total\n",
        "    return accuracy, loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <h2>`next_id`</h2> This function generates a unique name for model. `uuid4` does not generate duplicated but we are using a fixed `seed` hence we insure this name does not already exists.\n",
        "\n",
        "from uuid import uuid4\n",
        "import os\n",
        "def next_id(log_path):\n",
        "  if os.path.exists(log_path):\n",
        "    df = pd.read_csv(log_path)\n",
        "    while True:\n",
        "      uuid = str(uuid4())\n",
        "      if uuid not in df[\"model_name\"].values:\n",
        "        return uuid\n",
        "  else:\n",
        "    return str(uuid4())"
      ],
      "metadata": {
        "id": "h0cP5xZYNir5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def get_current_time():\n",
        "  now = datetime.now()\n",
        "\n",
        "  formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\") # Format the date and time as a string\n",
        "\n",
        "  return formatted_date_time\n",
        "\n",
        "def global_model_name_path_generator():\n",
        "\n",
        "  model_name = next_id(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "\n",
        "  path = \"/content/drive/MyDrive/MLDL_FederatedLearning/models/global/\" + model_name + \".pth\"\n",
        "\n",
        "  return model_name, path\n",
        "\n"
      ],
      "metadata": {
        "id": "Cxj5c-BT2GzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def del_model(model_name):\n",
        "  log_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  filter = log_df[\"model_name\"] == model_name\n",
        "  if not filter.any():\n",
        "    print(f\"recored ({model_name}) not found.\")\n",
        "    return\n",
        "  if os.path.exists(log_df[filter][\"path\"].values[0]):\n",
        "    os.remove(log_df[filter][\"path\"].values[0])\n",
        "  else:\n",
        "    print(\"model not found\")\n",
        "\n",
        "\n",
        "  if not np.isnan(log_df[filter][\"momentum_vector_path\"].values[0])  and os.path.exists(log_df[filter][\"momentum_vector_path\"].values[0]):\n",
        "    os.remove(log_df[filter][\"momentum_vector_path\"].values[0])\n",
        "  else:\n",
        "    print(\"momentum vector not found\")\n",
        "  log_df = log_df[~filter]\n",
        "  log_df.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\", index=False)\n",
        "# del_model(\"54ba3a96-df4d-4e55-bea1-fa8547aff906\")"
      ],
      "metadata": {
        "id": "tyK9f4bQcaO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9424ce1-e8d3-4d29-a279-5a8b3e22f88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title use this block to modify the global log file\n",
        "# temp = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "# temp[\"aggregation_method\"] =[ np.nan] * len(temp)\n",
        "# temp[\"contributors\"] =[ np.nan] * len(temp)\n",
        "# temp[\"momentum_vector_path\"] = [np.nan] * len(temp)\n",
        "\n",
        "# temp = temp[['backbone',\n",
        "#               'num_of_clients',\n",
        "#               'splitting_method',\n",
        "#               'aggregation_method',\n",
        "#               'Measurement_criteria',\n",
        "#               'accuracy',\n",
        "#               'loss',\n",
        "#               'size_of_dataset',\n",
        "#               'train_test_ratio',\n",
        "#               'classes',\n",
        "#               'round_number',\n",
        "#               'num_of_participants',\n",
        "#               'model_name',\n",
        "#               'prev_global_model_name',\n",
        "#               \"contributors\",\n",
        "#               'path',\n",
        "#               \"momentum_vector_path\",\n",
        "#               'path_to_subsets',\n",
        "#               'path_to_class_combs',\n",
        "#               'time'\n",
        "#                ]]\n",
        "# temp.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\", index=False)\n",
        "# temp.head()\n",
        "# del temp"
      ],
      "metadata": {
        "id": "rQycAoeYsIST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <h1>Select aggregation method </h1>\n",
        "#@markdown This value will be auto assigned in case the initial model of filtered clients have been aggregated with a spicific aggregation function in the previous rounds\n",
        "\n",
        "aggregation_method = \"EMA\"   #@param[\"FebAvg\",\"FebAvgM\", \"EMA\" ]\n",
        "\n",
        "prev_agg_method = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "filter = prev_agg_method[\"model_name\"] == initial_model_name\n",
        "prev_agg_method = prev_agg_method[filter]\n",
        "\n",
        "prev_agg_method = prev_agg_method[\"aggregation_method\"].values[0]\n",
        "aggregation_method = aggregation_method if np.isnan( prev_agg_method) else prev_agg_method\n",
        "\n",
        "\n",
        "print(f\"{aggregation_method} has been selected as the Aggregation function.\")"
      ],
      "metadata": {
        "id": "EZz-567w9qCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91e4ca9-b78d-47f7-fa2b-e7fa2cd8bc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMA has been selected as the Aggregation function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKHoyBtaN3-",
        "outputId": "2c0fed7f-9c43-4211-aa9e-0c3894e62022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected feature dimontion: 384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-53bd73a78147>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(paths.iloc[index]) # load state dict regarding the client number 'index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accurace:52.48\n",
            "Loss:1.89\n"
          ]
        }
      ],
      "source": [
        "if aggregation_method == \"FebAvg\":\n",
        "  global_model = feb_avg(filtered_clients_data)\n",
        "elif aggregation_method == \"FebAvgM\":\n",
        "  global_model,momentum_vector = feb_avg_m(filtered_clients_data)\n",
        "elif aggregation_method == \"EMA\":\n",
        "  global_model,momentum_vector = ema(filtered_clients_data)\n",
        "\n",
        "\n",
        "\n",
        "model_name, path = global_model_name_path_generator()\n",
        "\n",
        "test_accracy, test_loss= evaluation(global_model, test_loader)\n",
        "print(f\"Accurace:{test_accracy:.2f}\")\n",
        "print(f\"Loss:{test_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "log_path = \"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\"\n",
        "\n",
        "prev_global_model_name = filtered_clients_data[\"initial_model_name\"].values[0]\n",
        "global_model_log = filtered_clients_data.drop([\"client_id\",\"train_loss\",\"client_train_size\",\"client_test_size\",\"duration\",],axis=1)\n",
        "global_model_log = global_model_log.iloc[0]\n",
        "global_model_log[\"num_of_participants\"] = len(filtered_clients_data)\n",
        "global_model_log[\"prev_global_model_name\"] = initial_model_name\n",
        "global_model_log[\"model_name\"]= model_name\n",
        "global_model_log[\"accuracy\"] = test_accracy\n",
        "global_model_log[\"loss\"] = test_loss\n",
        "global_model_log[\"time\"] = get_current_time()\n",
        "global_model_log[\"path\"] = path\n",
        "global_model_log[\"Measurement_criteria\"] = \"accuracy,loss\"\n",
        "global_model_log[\"contributors\"] = contributors\n",
        "global_model_log[\"aggregation_method\"] = aggregation_method\n",
        "\n",
        "if aggregation_method == \"FebAvg\":\n",
        "  global_model_log[\"momentum_vector_path\"] = None\n",
        "\n",
        "elif aggregation_method == \"FebAvgM\" or aggregation_method == \"EMA\":\n",
        "  global_model_log[\"momentum_vector_path\"] = \"/content/drive/MyDrive/MLDL_FederatedLearning/models/global/momentun_vectors/MV_\"+ model_name + \".pt\"\n",
        "  torch.save(momentum_vector, global_model_log[\"momentum_vector_path\"])\n",
        "\n",
        "\n",
        "global_model_log = pd.DataFrame(global_model_log).T\n",
        "global_model_log = global_model_log[['backbone',\n",
        "              'num_of_clients',\n",
        "              'splitting_method',\n",
        "              'aggregation_method',\n",
        "              'Measurement_criteria',\n",
        "              'accuracy',\n",
        "              'loss',\n",
        "              'size_of_dataset',\n",
        "              'train_test_ratio',\n",
        "              'classes',\n",
        "              'round_number',\n",
        "              'num_of_participants',\n",
        "              'model_name',\n",
        "              'prev_global_model_name',\n",
        "              \"contributors\",\n",
        "              'path',\n",
        "              \"momentum_vector_path\",\n",
        "              'path_to_subsets',\n",
        "              'path_to_class_combs',\n",
        "              'time'\n",
        "               ]]\n",
        "\n",
        "flag = False\n",
        "if os.path.exists(path):\n",
        "  print(\"Model already exist\")\n",
        "  flag = True\n",
        "\n",
        "if os.path.exists(log_path):\n",
        "  global_log_df = pd.read_csv(log_path)\n",
        "  if model_name in global_log_df[\"model_name\"].values:\n",
        "    print(\"record already exist\")\n",
        "    flag = True\n",
        "  if not flag:\n",
        "    global_model_log.to_csv(log_path, mode='a', header=False, index=False)\n",
        "else:\n",
        "  if not flag:\n",
        "    global_model_log.to_csv(log_path, index=False, header=True)\n",
        "\n",
        "\n",
        "if not flag:\n",
        "  torch.save(global_model.state_dict(),  path )\n",
        "  if aggregation_method == \"FebAvgM\" or aggregation_method == \"EMA\":\n",
        "    torch.save(momentum_vector, global_model_log[\"momentum_vector_path\"].values[0])\n"
      ],
      "metadata": {
        "id": "MSUmG3St1bgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_model_log.head()"
      ],
      "metadata": {
        "id": "2m5N00jlJbL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "59a1790e-3a30-4022-ddbb-0954b114cdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      backbone num_of_clients splitting_method aggregation_method  \\\n",
              "0  dino_vits16             20   i.i.d. sharing                EMA   \n",
              "\n",
              "  Measurement_criteria accuracy      loss size_of_dataset  \\\n",
              "0        accuracy,loss    52.48  1.892683           50000   \n",
              "\n",
              "              train_test_ratio classes round_number num_of_participants  \\\n",
              "0  {'train': 0.8, 'test': 0.2}     all            1                   1   \n",
              "\n",
              "                             model_name                prev_global_model_name  \\\n",
              "0  319c9647-1873-41d6-9e9d-9ae50c85a033  db569e2d-3e81-4b69-bc11-a708fd499ca7   \n",
              "\n",
              "                             contributors  \\\n",
              "0  [4413e8c9-56df-475c-b6ab-cf4da68d8f31]   \n",
              "\n",
              "                                                path  \\\n",
              "0  /content/drive/MyDrive/MLDL_FederatedLearning/...   \n",
              "\n",
              "                                momentum_vector_path  \\\n",
              "0  /content/drive/MyDrive/MLDL_FederatedLearning/...   \n",
              "\n",
              "                                     path_to_subsets path_to_class_combs  \\\n",
              "0  /content/drive/MyDrive/MLDL_FederatedLearning/...                 NaN   \n",
              "\n",
              "                  time  \n",
              "0  2025-06-10 23:30:10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-020e8f7f-f719-4625-b1a5-ce61808c0e82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>backbone</th>\n",
              "      <th>num_of_clients</th>\n",
              "      <th>splitting_method</th>\n",
              "      <th>aggregation_method</th>\n",
              "      <th>Measurement_criteria</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>size_of_dataset</th>\n",
              "      <th>train_test_ratio</th>\n",
              "      <th>classes</th>\n",
              "      <th>round_number</th>\n",
              "      <th>num_of_participants</th>\n",
              "      <th>model_name</th>\n",
              "      <th>prev_global_model_name</th>\n",
              "      <th>contributors</th>\n",
              "      <th>path</th>\n",
              "      <th>momentum_vector_path</th>\n",
              "      <th>path_to_subsets</th>\n",
              "      <th>path_to_class_combs</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dino_vits16</td>\n",
              "      <td>20</td>\n",
              "      <td>i.i.d. sharing</td>\n",
              "      <td>EMA</td>\n",
              "      <td>accuracy,loss</td>\n",
              "      <td>52.48</td>\n",
              "      <td>1.892683</td>\n",
              "      <td>50000</td>\n",
              "      <td>{'train': 0.8, 'test': 0.2}</td>\n",
              "      <td>all</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>319c9647-1873-41d6-9e9d-9ae50c85a033</td>\n",
              "      <td>db569e2d-3e81-4b69-bc11-a708fd499ca7</td>\n",
              "      <td>[4413e8c9-56df-475c-b6ab-cf4da68d8f31]</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>/content/drive/MyDrive/MLDL_FederatedLearning/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-06-10 23:30:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-020e8f7f-f719-4625-b1a5-ce61808c0e82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-020e8f7f-f719-4625-b1a5-ce61808c0e82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-020e8f7f-f719-4625-b1a5-ce61808c0e82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "global_model_log",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}