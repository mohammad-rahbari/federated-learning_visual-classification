{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-rahbari/federated-learning_visual-classification/blob/main/notebooks/Federated_learning_server_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and data"
      ],
      "metadata": {
        "id": "QH6umXWdxe2I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wpogmY-iMNWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f090eb0f-4075-4799-db23-9b0f59dbcdec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ve754mVLEmoO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F83IfINuLwqq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df628e2f-68f6-4768-c9dc-a8185908e869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [01:04<00:00, 2.62MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title In this block we import the test set of CIFAR100 to evaluate the global model\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting data of models we want to aggregate"
      ],
      "metadata": {
        "id": "Illl7SphzfXZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lQB4dFXLUIp7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "initial_model_name = \"61c76e8b-60bf-4f13-841a-6ddcdf1f9ca1\" #@param{\"type\":\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AhE739SgMX_4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Client's log file has been loaded in this block so we can use it in next steps\n",
        "clients_data = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/client_log.csv\")\n",
        "# clients_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhoHGiZVUDgo",
        "outputId": "54c9e1c5-eecc-40fd-ee3e-bcd89124defa",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of all trained clients: 660\n",
            "Number of clients after filtering: 12\n",
            "Contributors: ['6c897048-56de-4cb3-9fbc-32517c851297', 'a521a697-d04b-430a-987d-bc8ec036b039', 'fefb9d6d-def4-4bce-b469-79b6015dd4e2', '5c49729c-89de-4b7d-a88b-33b989224b29', '91ad49c6-b505-436f-89f9-5032b0232543', 'd0d95658-bed9-4380-863d-dd3ec94c681d', 'dc6ecbd8-2055-46c6-a985-e409ed06c2d4', '4954dd53-02b8-45b9-bf7d-d55415e7dedc', '6b8212a7-412d-4759-9080-938ede779669', 'e1ca9db3-23f7-4d8f-8262-27442993d6c2', '2d91334f-981e-4ccf-8444-a57d50b4671b', 'fde3fbe2-8bc4-49c0-80c3-3794cb39c651']\n"
          ]
        }
      ],
      "source": [
        "#@title gets the clients\n",
        "filter =  clients_data['initial_model_name']== initial_model_name\n",
        "filtered_clients_data = clients_data[filter] # Using filter to collect clients with specified initial model\n",
        "params = filtered_clients_data[['backbone',\n",
        "                                    'num_of_clients',\n",
        "                                    'splitting_method',\n",
        "                                    'size_of_dataset']]\n",
        "params = dict(params.iloc[0])\n",
        "print(\"Number of all trained clients:\", len(clients_data))\n",
        "print(\"Number of clients after filtering:\", len(filtered_clients_data))\n",
        "contributors = [] # contributors is being used to store the name of models which contributes in aggregation\n",
        "for i  in filtered_clients_data['model_name'].values:\n",
        "  contributors.append(i)\n",
        "print(\"Contributors:\", contributors)\n",
        "# filtered_clients_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7j78bLPfZmAU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Dino Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DinoClassifier(nn.Module):\n",
        "  def __init__(self, backbone, num_classes:int=100, device=None):\n",
        "    super(DinoClassifier, self).__init__()\n",
        "    self.backbone = torch.hub.load('facebookresearch/dino:main', backbone)\n",
        "\n",
        "\n",
        "    #We need to freaze thhe parameters of bakbone first so we can train only on the head layer(output layer)\n",
        "    for param in self.backbone.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    #determine the Device\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.backbone.to(device)\n",
        "\n",
        "    #To detect the output feature dimontion of backbone we run  Dummy forward pass\n",
        "    with torch.no_grad():\n",
        "\n",
        "      dummy_input = torch.randn(1,3,224,224).to(device)\n",
        "      dummy_out = self.backbone(dummy_input)\n",
        "\n",
        "\n",
        "      if isinstance(dummy_out, tuple):\n",
        "        dummy_out = dummy_out[0]\n",
        "      elif isinstance(dummy_out, dict):\n",
        "        dummy_out = dummy_out.get(\"x_norm_clstoken\", next(iter(dummy_out.values())))\n",
        "\n",
        "      #If the output is 3D (B, T, D), we assume first token is the [CLS] token.\n",
        "      if dummy_out.dim() == 3:\n",
        "        dummy_feature = dummy_out[:,0]\n",
        "      else:\n",
        "        dummy_feature = dummy_out\n",
        "      feature_dim = dummy_feature.shape[1]\n",
        "      print(\"Detected feature dimontion:\", feature_dim)\n",
        "\n",
        "\n",
        "      #Hidden Layer\n",
        "      self.hidden = nn.Sequential(\n",
        "          nn.Linear(feature_dim, 128),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "\n",
        "      #Difineing the classification Head\n",
        "      self.head = nn.Linear(128, num_classes)\n",
        "\n",
        "      #Ensure the head is trainable.\n",
        "      for param in self.hidden.parameters():\n",
        "        param.requires_grad = True\n",
        "      for param in self.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #pass the input through the backbone\n",
        "    features = self.backbone(x)\n",
        "\n",
        "    if isinstance(features, tuple):\n",
        "      features = features[0]\n",
        "    elif isinstance(features, dict):\n",
        "      features = features.get(\"x_norm_clstoken\", next(iter(features.values())))\n",
        "\n",
        "\n",
        "    # If featers are retuened as (B, T, D), use the first token\n",
        "    if features.dim() == 3:\n",
        "      features = features[:,0]\n",
        "\n",
        "\n",
        "    hidden_out  = self.hidden(features)\n",
        "\n",
        "    logits = self.head(hidden_out)\n",
        "\n",
        "    return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UDoFGHyOXo-K"
      },
      "outputs": [],
      "source": [
        "# @title `get_model` function retrieves and loads the models of filtered clients\n",
        "def get_model(paths,criterion, backbone):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = DinoClassifier(backbone=backbone, num_classes=100, device=device) # Loading an initial custom dino model\n",
        "  for index in range(len(paths)):\n",
        "    state_dict = torch.load(paths.iloc[index]) # load state dict regarding the client number 'index'\n",
        "    model.head.load_state_dict(state_dict[\"head\"]) # set the state dict based on client\n",
        "    model.hidden.load_state_dict(state_dict[\"hidden\"]) # set the state dict based on client\n",
        "\n",
        "    model.to(device)\n",
        "    yield (model,criterion.iloc[index]) # this command throws model one at the time so less time and resouces will be used\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregation functions\n",
        "\n",
        "Implemented algorithm:\n",
        "\n",
        "*   FedAvg\n",
        "*   FedAvgM\n",
        "*   EMA\n",
        "*   FedQ\n",
        "\n"
      ],
      "metadata": {
        "id": "bqUWwoTVBcgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <h2>FebAvg</h2>\n",
        "def feb_avg(df):\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if global_weights[\"head\"] is None:\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        global_model = copy.deepcopy(model)\n",
        "        for k in global_weights[\"head\"].keys():\n",
        "          global_weights[\"head\"][k].zero_() # This command sets the tensor to zero\n",
        "        for k in global_weights[\"hidden\"].keys():\n",
        "          global_weights[\"hidden\"][k].zero_() # This command sets the tensor to zero\n",
        "\n",
        "      for k in global_weights[\"head\"].keys():\n",
        "        global_weights[\"head\"][k] += model.head.state_dict()[k] * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "      for k in global_weights[\"hidden\"].keys():\n",
        "        global_weights[\"hidden\"][k] += model.hidden.state_dict()[k] * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "    global_model.head.load_state_dict(global_weights[\"head\"]) # A model with modified head will be assignd\n",
        "    global_model.hidden.load_state_dict(global_weights[\"hidden\"]) # A model with modified hidden will be assignd\n",
        "  return global_model\n",
        "\n"
      ],
      "metadata": {
        "id": "1wDV2Y3-OKlS",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FebAvgM\n",
        "def feb_avg_m(df, momentum_coefficient=0.9, momentum_vector_path= None):\n",
        "\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  delta = {\"head\":None, \"hidden\":None} # `delta` is variable that keep the average of clients\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if delta['head'] is None:\n",
        "\n",
        "        global_model = copy.deepcopy(model)\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        delta[\"head\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"head\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "        delta[\"hidden\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"hidden\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "\n",
        "\n",
        "      client_head = model.head.state_dict()\n",
        "      for k in delta['head'].keys():\n",
        "        delta['head'][k] += (client_head[k] - global_weights[\"head\"][k]) * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "\n",
        "      client_hidden = model.hidden.state_dict()\n",
        "      for k in delta['hidden'].keys():\n",
        "        delta['hidden'][k] += (client_hidden[k] - global_weights[\"hidden\"][k]) * (sample_size / total_samples) # Each weight\n",
        "\n",
        "    # In this section we calculate the momentum_vector\n",
        "\n",
        "\n",
        "    if momentum_vector_path is None:\n",
        "      momentum_vector = {\n",
        "          \"head\": {k: delta[\"head\"][k].clone() for k in delta[\"head\"]},\n",
        "          \"hidden\": {k: delta[\"hidden\"][k].clone() for k in delta[\"hidden\"]}\n",
        "      }\n",
        "    else:\n",
        "      momentum_vector = torch.load(momentum_vector_path) #In rounds > 1 momentum vector is requerd to be loaded from drive\n",
        "      for k in delta['head'].keys():\n",
        "        momentum_vector['head'][k] = momentum_coefficient * momentum_vector['head'][k]  + delta['head'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "      for k in delta['hidden'].keys():\n",
        "        momentum_vector['hidden'][k] = momentum_coefficient * momentum_vector['hidden'][k]  + delta['hidden'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    global_head = copy.deepcopy(global_model.head.state_dict())\n",
        "    for k in momentum_vector['head'].keys():\n",
        "      global_head[k] =global_head[k] + momentum_vector['head'][k] #After adding momentum vector the last global model we use clamp function we insure to keep momentum vector in boundary\n",
        "    global_hidden = copy.deepcopy(global_model.hidden.state_dict())\n",
        "    for k in momentum_vector['hidden'].keys():\n",
        "      global_hidden[k] = global_hidden[k] + momentum_vector['hidden'][k]#After adding momentum vector the last global model we use clamp function\n",
        "\n",
        "\n",
        "    global_model.head.load_state_dict(global_head)\n",
        "    global_model.hidden.load_state_dict(global_hidden)\n",
        "\n",
        "\n",
        "  return global_model, momentum_vector # We return momentum_vector to save it and use for next aggregation steps\n",
        "\n"
      ],
      "metadata": {
        "id": "sNxSyQmpOMFJ",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title EMA\n",
        "def EMA(df, decay=0.9, momentum_vector_path= None):\n",
        "\n",
        "  total_samples = df[\"client_train_size\"].sum() # Calculate the total number of samples of clients wich had contributed\n",
        "  delta = {\"head\":None, \"hidden\":None} # `delta` is variable that keep the average of clients\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"],df[\"client_train_size\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, sample_size in models:\n",
        "      if delta['head'] is None:\n",
        "\n",
        "        global_model = copy.deepcopy(model)\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        delta[\"head\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"head\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "        delta[\"hidden\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"hidden\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "\n",
        "\n",
        "      client_head = model.head.state_dict()\n",
        "      for k in delta['head'].keys():\n",
        "        delta['head'][k] += (client_head[k] - global_weights[\"head\"][k]) * (sample_size / total_samples) # Each weight will be assgin by average of all clients weights\n",
        "\n",
        "      client_hidden = model.hidden.state_dict()\n",
        "      for k in delta['hidden'].keys():\n",
        "        delta['hidden'][k] += (client_hidden[k] - global_weights[\"hidden\"][k]) * (sample_size / total_samples) # Each weight\n",
        "\n",
        "    # In this section we calculate the momentum_vector\n",
        "\n",
        "\n",
        "    if momentum_vector_path is None:\n",
        "      momentum_vector = {\n",
        "          \"head\": {k: delta[\"head\"][k].clone() for k in delta[\"head\"]},\n",
        "          \"hidden\": {k: delta[\"hidden\"][k].clone() for k in delta[\"hidden\"]}\n",
        "      }\n",
        "    else:\n",
        "      momentum_vector = torch.load(momentum_vector_path) #In rounds > 1 momentum vector is requerd to be loaded from drive\n",
        "      for k in delta['head'].keys():\n",
        "\n",
        "        momentum_vector['head'][k] = decay * momentum_vector['head'][k]  + (1- decay) *  delta['head'][k]  # Using the the formula of EMA we calculate the momentum vector\n",
        "      for k in delta['hidden'].keys():\n",
        "        momentum_vector['hidden'][k] = decay * momentum_vector['hidden'][k]  + (1- decay) *  delta['hidden'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    global_head = copy.deepcopy(global_model.head.state_dict())\n",
        "    for k in momentum_vector['head'].keys():\n",
        "      global_head[k] =global_head[k] + momentum_vector['head'][k] #After adding momentum vector the last global model we use clamp function we insure to keep momentum vector in boundary\n",
        "    global_hidden = copy.deepcopy(global_model.hidden.state_dict())\n",
        "    for k in momentum_vector['hidden'].keys():\n",
        "      global_hidden[k] = global_hidden[k] + momentum_vector['hidden'][k]#After adding momentum vector the last global model we use clamp function\n",
        "\n",
        "\n",
        "    global_model.head.load_state_dict(global_head)\n",
        "    global_model.hidden.load_state_dict(global_hidden)\n",
        "\n",
        "\n",
        "  return global_model, momentum_vector # We return momentum_vector to save it and use for next aggregation steps\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyQ9s1udbhJI",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FedQ\n",
        "def minmax(series):\n",
        "    min_val, max_val = series.min(), series.max()\n",
        "    if min_val == max_val:\n",
        "        return pd.Series([1.0] * len(series), index=series.index)\n",
        "    return (series - min_val) / (max_val - min_val)\n",
        "\n",
        "def FedQ(data, decay=0.9, momentum_vector_path= None):\n",
        "  alpha = 0.5\n",
        "  df = data.copy()\n",
        "  df[\"sample_size_scaled\"] = minmax(df[\"client_train_size\"])\n",
        "  df[\"acc_scaled\"] = minmax(df[\"accuracy\"])\n",
        "\n",
        "  df[\"avg_criterion\"] = alpha * df[\"acc_scaled\"] + (1 - alpha) * df[\"sample_size_scaled\"]\n",
        "\n",
        "  total_sum = df[\"avg_criterion\"].sum()\n",
        "\n",
        "  delta = {\"head\":None, \"hidden\":None} # `delta` is variable that keep the average of clients\n",
        "  global_weights = {\"head\":None, \"hidden\":None} # This variable stores the weights we want to modify\n",
        "\n",
        "  models = get_model(df[\"path\"], df[\"avg_criterion\"], df.iloc[0][\"backbone\"])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for model, avg_criterion in models:\n",
        "      if delta['head'] is None:\n",
        "\n",
        "        global_model = copy.deepcopy(model)\n",
        "        global_weights[\"head\"] = copy.deepcopy(model.head.state_dict())\n",
        "        global_weights[\"hidden\"] = copy.deepcopy(model.hidden.state_dict())\n",
        "        delta[\"head\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"head\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "        delta[\"hidden\"] = { k: torch.zeros_like(v) for k, v in global_weights[\"hidden\"].items() } # A dict with structure of the model that we want to modify will be generated\n",
        "\n",
        "\n",
        "      client_head = model.head.state_dict()\n",
        "      for k in delta['head'].keys():\n",
        "        delta['head'][k] += (client_head[k] - global_weights[\"head\"][k]) * (avg_criterion / total_sum) # Each weight will be assgin by average of all clients weights\n",
        "\n",
        "      client_hidden = model.hidden.state_dict()\n",
        "      for k in delta['hidden'].keys():\n",
        "        delta['hidden'][k] += (client_hidden[k] - global_weights[\"hidden\"][k]) * (avg_criterion / total_sum) # Each weight\n",
        "\n",
        "    # In this section we calculate the momentum_vector\n",
        "\n",
        "\n",
        "    if momentum_vector_path is None:\n",
        "      momentum_vector = {\n",
        "          \"head\": {k: delta[\"head\"][k].clone() for k in delta[\"head\"]},\n",
        "          \"hidden\": {k: delta[\"hidden\"][k].clone() for k in delta[\"hidden\"]}\n",
        "      }\n",
        "    else:\n",
        "      momentum_vector = torch.load(momentum_vector_path) #In rounds > 1 momentum vector is requerd to be loaded from drive\n",
        "      for k in delta['head'].keys():\n",
        "\n",
        "        momentum_vector['head'][k] = decay * momentum_vector['head'][k]  + (1- decay) *  delta['head'][k]  # Using the the formula of EMA we calculate the momentum vector\n",
        "      for k in delta['hidden'].keys():\n",
        "        momentum_vector['hidden'][k] = decay * momentum_vector['hidden'][k]  + (1- decay) *  delta['hidden'][k]  # Using the the formula of FebAvgM we calculate the momentum vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    global_head = copy.deepcopy(global_model.head.state_dict())\n",
        "    for k in momentum_vector['head'].keys():\n",
        "      global_head[k] =global_head[k] + momentum_vector['head'][k] #After adding momentum vector the last global model we use clamp function we insure to keep momentum vector in boundary\n",
        "    global_hidden = copy.deepcopy(global_model.hidden.state_dict())\n",
        "    for k in momentum_vector['hidden'].keys():\n",
        "      global_hidden[k] = global_hidden[k] + momentum_vector['hidden'][k]#After adding momentum vector the last global model we use clamp function\n",
        "\n",
        "\n",
        "    global_model.head.load_state_dict(global_head)\n",
        "    global_model.hidden.load_state_dict(global_hidden)\n",
        "\n",
        "\n",
        "  return global_model, momentum_vector # We return momentum_vector to save it and use for next aggregation steps\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mQ6G6AHfmUDR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jTG0_BCipHwT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title This function will evaluate the model.</br> The outputs are loss and accuracy\n",
        "def evaluation(model, data_loader):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  test_loss = 0\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in  data_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, prediction = torch.max(outputs.data,1)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item() * labels.size(0)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (prediction == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    loss = test_loss / total\n",
        "    return accuracy, loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <h2>`next_id`</h2> This function generates a unique name for model. `uuid4` does not generate duplicated but we are using a fixed `seed` hence we insure this name does not already exists.\n",
        "\n",
        "from uuid import uuid4\n",
        "import os\n",
        "def next_id(log_path):\n",
        "  if os.path.exists(log_path):\n",
        "    df = pd.read_csv(log_path)\n",
        "    while True:\n",
        "      uuid = str(uuid4())\n",
        "      if uuid not in df[\"model_name\"].values:\n",
        "        return uuid\n",
        "  else:\n",
        "    return str(uuid4())"
      ],
      "metadata": {
        "id": "h0cP5xZYNir5",
        "cellView": "form"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title _\n",
        "from datetime import datetime\n",
        "\n",
        "def get_current_time():\n",
        "  now = datetime.now()\n",
        "\n",
        "  formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\") # Format the date and time as a string\n",
        "\n",
        "  return formatted_date_time\n",
        "\n",
        "def global_model_name_path_generator():\n",
        "\n",
        "  model_name = next_id(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "\n",
        "  path = \"/content/drive/MyDrive/MLDL_FederatedLearning/models/global/\" + model_name + \".pth\"\n",
        "\n",
        "  return model_name, path\n",
        "\n"
      ],
      "metadata": {
        "id": "Cxj5c-BT2GzK",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title delete model\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def del_model(model_name):\n",
        "  log_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "  filter = log_df[\"model_name\"] == model_name\n",
        "  if not filter.any():\n",
        "    print(f\"recored ({model_name}) not found.\")\n",
        "    return\n",
        "  if os.path.exists(log_df[filter][\"path\"].values[0]):\n",
        "    os.remove(log_df[filter][\"path\"].values[0])\n",
        "  else:\n",
        "    print(\"model not found\")\n",
        "\n",
        "\n",
        "  try:\n",
        "    os.remove(log_df[filter][\"momentum_vector_path\"].values[0])\n",
        "  except:\n",
        "    print(\"momentum vector not found\")\n",
        "  log_df = log_df[~filter]\n",
        "  log_df.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\", index=False)\n",
        "# del_model(\"e3435947-ad6e-4ca2-8408-390021b33a18\")"
      ],
      "metadata": {
        "id": "tyK9f4bQcaO0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title use this block to modify the global log file\n",
        "# temp = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "# temp[\"aggregation_method\"] =[ np.nan] * len(temp)\n",
        "# temp[\"contributors\"] =[ np.nan] * len(temp)\n",
        "# temp[\"momentum_vector_path\"] = [np.nan] * len(temp)\n",
        "\n",
        "# temp = temp[['backbone',\n",
        "#               'num_of_clients',\n",
        "#               'splitting_method',\n",
        "#               'aggregation_method',\n",
        "#               'Measurement_criteria',\n",
        "#               'accuracy',\n",
        "#               'loss',\n",
        "#               'size_of_dataset',\n",
        "#               'train_test_ratio',\n",
        "#               'classes',\n",
        "#               'round_number',\n",
        "#               'num_of_participants',\n",
        "#               'model_name',\n",
        "#               'prev_global_model_name',\n",
        "#               \"contributors\",\n",
        "#               'path',\n",
        "#               \"momentum_vector_path\",\n",
        "#               'path_to_subsets',\n",
        "#               'path_to_class_combs',\n",
        "#               'time'\n",
        "#                ]]\n",
        "# temp.to_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\", index=False)\n",
        "# temp.head()\n",
        "# del temp"
      ],
      "metadata": {
        "id": "rQycAoeYsIST",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <h1>Select aggregation method </h1>\n",
        "#@markdown This value will be auto assigned in case the initial model of filtered clients have been aggregated with a spicific aggregation function in the previous rounds\n",
        "\n",
        "aggregation_method = \"FedQ\"   #@param[\"FebAvg\",\"FebAvgM\", \"EMA\",\"FedQ\" ]\n",
        "\n",
        "prev_agg_method = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "\n",
        "filter = prev_agg_method[\"model_name\"] == initial_model_name\n",
        "prev_agg_method = prev_agg_method[filter]\n",
        "\n",
        "prev_agg_method = prev_agg_method[\"aggregation_method\"].values[0]\n",
        "\n",
        "aggregation_method = aggregation_method if not type(prev_agg_method) == type(\"str\") else prev_agg_method\n",
        "\n",
        "\n",
        "print(f\"{aggregation_method} has been selected as the Aggregation function.\")"
      ],
      "metadata": {
        "id": "EZz-567w9qCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9226cf22-56ad-4598-8724-76b53f67984f",
        "cellView": "form"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedQ has been selected as the Aggregation function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "7ZKHoyBtaN3-",
        "outputId": "4ac84f72-cee7-4e38-cd7d-7e6a12e5089c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-690545916.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"sample_size_scaled\"] = minmax(df[\"client_train_size\"])\n",
            "/tmp/ipython-input-12-690545916.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"acc_scaled\"] = minmax(df[\"accuracy\"])\n",
            "/tmp/ipython-input-12-690545916.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"avg_criterion\"] = alpha * df[\"acc_scaled\"] + (1 - alpha) * df[\"sample_size_scaled\"]\n",
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 208MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected feature dimontion: 384\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-3418245119.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_model_name_path_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtest_accracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accurace:{test_accracy:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss:{test_loss:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-2124399330.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Aggregation\n",
        "if aggregation_method == \"FebAvg\":\n",
        "  global_model = feb_avg(filtered_clients_data)\n",
        "elif aggregation_method == \"FebAvgM\":\n",
        "  global_model,momentum_vector = feb_avg_m(filtered_clients_data)\n",
        "elif aggregation_method == \"EMA\":\n",
        "  global_model,momentum_vector = EMA(filtered_clients_data)\n",
        "elif aggregation_method == \"FedQ\":\n",
        "  global_model,momentum_vector = FedQ(filtered_clients_data)\n",
        "else:\n",
        "  print(\"Invalid aggregation method\")\n",
        "\n",
        "\n",
        "model_name, path = global_model_name_path_generator()\n",
        "\n",
        "test_accracy, test_loss= evaluation(global_model, test_loader)\n",
        "print(f\"Accurace:{test_accracy:.2f}\")\n",
        "print(f\"Loss:{test_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Saves new generated global model\n",
        "import os\n",
        "log_path = \"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\"\n",
        "\n",
        "prev_global_model_name = filtered_clients_data[\"initial_model_name\"].values[0]\n",
        "global_model_log = filtered_clients_data.drop([\"client_id\",\"train_loss\",\"client_train_size\",\"client_test_size\",\"duration\",],axis=1)\n",
        "global_model_log = global_model_log.iloc[0]\n",
        "global_model_log[\"num_of_participants\"] = len(filtered_clients_data)\n",
        "global_model_log[\"prev_global_model_name\"] = initial_model_name\n",
        "global_model_log[\"model_name\"]= model_name\n",
        "global_model_log[\"accuracy\"] = test_accracy\n",
        "global_model_log[\"loss\"] = test_loss\n",
        "global_model_log[\"time\"] = get_current_time()\n",
        "global_model_log[\"path\"] = path\n",
        "global_model_log[\"Measurement_criteria\"] = \"accuracy,loss\"\n",
        "global_model_log[\"contributors\"] = contributors\n",
        "global_model_log[\"aggregation_method\"] = aggregation_method\n",
        "\n",
        "if aggregation_method == \"FebAvg\":\n",
        "  global_model_log[\"momentum_vector_path\"] = None\n",
        "\n",
        "elif aggregation_method == \"FebAvgM\" or aggregation_method == \"EMA\" or aggregation_method == \"FedQ\" :\n",
        "  global_model_log[\"momentum_vector_path\"] = \"/content/drive/MyDrive/MLDL_FederatedLearning/models/global/momentun_vectors/MV_\"+ model_name + \".pt\"\n",
        "  torch.save(momentum_vector, global_model_log[\"momentum_vector_path\"])\n",
        "\n",
        "\n",
        "global_model_log = pd.DataFrame(global_model_log).T\n",
        "global_model_log = global_model_log[['backbone',\n",
        "              'num_of_clients',\n",
        "              'splitting_method',\n",
        "              'aggregation_method',\n",
        "              'Measurement_criteria',\n",
        "              'accuracy',\n",
        "              'loss',\n",
        "              'size_of_dataset',\n",
        "              'train_test_ratio',\n",
        "              'classes',\n",
        "              'round_number',\n",
        "              'num_of_participants',\n",
        "              'model_name',\n",
        "              'prev_global_model_name',\n",
        "              \"contributors\",\n",
        "              'path',\n",
        "              \"momentum_vector_path\",\n",
        "              'path_to_subsets',\n",
        "              'path_to_class_combs',\n",
        "              'time'\n",
        "               ]]\n",
        "\n",
        "flag = False\n",
        "if os.path.exists(path):\n",
        "  print(\"Model already exist\")\n",
        "  flag = True\n",
        "\n",
        "if os.path.exists(log_path):\n",
        "  global_log_df = pd.read_csv(log_path)\n",
        "  if model_name in global_log_df[\"model_name\"].values:\n",
        "    print(\"record already exist\")\n",
        "    flag = True\n",
        "  if not flag:\n",
        "    global_model_log.to_csv(log_path, mode='a', header=False, index=False)\n",
        "else:\n",
        "  if not flag:\n",
        "    global_model_log.to_csv(log_path, index=False, header=True)\n",
        "\n",
        "\n",
        "if not flag:\n",
        "  torch.save(global_model.state_dict(),  path )\n",
        "  if aggregation_method == \"FebAvgM\" or aggregation_method == \"EMA\":\n",
        "    torch.save(momentum_vector, global_model_log[\"momentum_vector_path\"].values[0])\n"
      ],
      "metadata": {
        "id": "MSUmG3St1bgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OUTCOME"
      ],
      "metadata": {
        "id": "zsmJL2o_tJhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_model_log.head()"
      ],
      "metadata": {
        "id": "2m5N00jlJbL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "pre_df = pd.read_csv(\"/content/drive/MyDrive/MLDL_FederatedLearning/csv/global_log.csv\")\n",
        "pre_df = pre_df[pre_df['aggregation_method'] == \"FedQ\"]\n",
        "\n",
        "\n",
        "\n",
        "def my_plot(pre_df,column_name):\n",
        "  plt.figure(figsize=(10, 3))\n",
        "  plt.plot( pre_df[\"round_number\"],pre_df[column_name], \".-\" )\n",
        "\n",
        "  plt.grid(True)\n",
        "  plt.xlabel(\"round number\")\n",
        "  plt.ylabel(column_name)\n",
        "\n",
        "  plt.show()\n",
        "my_plot(pre_df,\"loss\")\n",
        "my_plot(pre_df,\"accuracy\")\n",
        "\n",
        "\n",
        "client_n_lst= list(clients_data[\"client_id\"].values)\n",
        "client_n_lst.sort()\n",
        "client_n_set  = list(set(client_n_lst))\n",
        "count_lst = []\n",
        "for i in range(len(client_n_set)):\n",
        "  count_lst.append(client_n_lst.count(client_n_set[i]))\n",
        "  client_n_set[i] = str(client_n_set[i])\n",
        "plt.figure(figsize=(30, 3))\n",
        "plt.bar(client_n_set,count_lst,color='skyblue')"
      ],
      "metadata": {
        "id": "jDZG9_F7o1Gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}