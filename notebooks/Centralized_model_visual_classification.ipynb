{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "fu0Iz0LDlRDK"
      ],
      "authorship_tag": "ABX9TyNb8DUW4xW87JZTVO/9sSql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-rahbari/federated-learning_visual-classification/blob/main/notebooks/Centralized_model_visual_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing DINO and installing its dependencies"
      ],
      "metadata": {
        "id": "fu0Iz0LDlRDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clon the DINO ripo\n",
        "!git clone https://github.com/facebookresearch/dino.git"
      ],
      "metadata": {
        "id": "IckKkLcG0zeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "31fbd1b5-8798-4e43-f729-5be623673361"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Total 175 (delta 0), reused 0 (delta 0), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (175/175), 24.47 MiB | 9.58 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Installing required dependencies regarding DINO\n",
        "%cd dino\n",
        "!pip install -r requirements.txt\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dY0yvkTfiNV3",
        "outputId": "511f03ec-d942-4770-a1d9-add4444fbdbf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dino\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# preprocessing the CIFAR-100 dataset\n",
        "\n",
        "feature size in CIFAR is 32x32 but DINO requires 224x224 in the input layer.\n",
        "\n",
        "In first step we upscale the dataset and then we add randomization to it\n",
        "\n",
        "In last step of transformation we normalize data usind mean value and standard division of ImageNet\n",
        "\n"
      ],
      "metadata": {
        "id": "M9hv0ik3jZ-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "dDodXJD_lPCd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])"
      ],
      "metadata": {
        "id": "_4ydT67FmAQR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "test_daataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_daataset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "CNgGMkqaqX-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766e9873-a2d6-4eef-f4f1-75f8db7184f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:14<00:00, 12.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and preparing the pretrained DINO model *(DINO-DeiT_Small)*"
      ],
      "metadata": {
        "id": "5FeYR3YRqqkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title loadig the model\n",
        "import torch.hub\n",
        "\n",
        "dino_model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "# dino_model = torch.hub.load('facebookresearch/dino:main', 'dino_xcit_small_12_p16')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pmioa5SdrO4j",
        "outputId": "160b9df7-47a6-45cd-b8d1-c4f06e44557b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 317MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Configuration\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DinoClassifire(nn.Module):\n",
        "  def __init__(self, dino_model, num_classes:int=100, device=None):\n",
        "    super(DinoClassifire, self).__init__()\n",
        "    self.backbone = dino_model\n",
        "\n",
        "    #We need to freaze thhe parameters of bakbone first so we can train only on the head layer(output layer)\n",
        "    for param in self.backbone.parameters():\n",
        "      param.requiers_grad = False\n",
        "\n",
        "    #determine the Device\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.backbone.to(device)\n",
        "\n",
        "    #To detect the output feature dimontion of backbone we run  Dummy forward pass\n",
        "    with torch.no_grad():\n",
        "      dummy_input = torch.randn(1,3,224,224).to(device)\n",
        "      dummy_out = self.backbone(dummy_input)\n",
        "\n",
        "\n",
        "      #If the output is 3D (B, T, D), we assume first token is the [CLS] token.\n",
        "      if dummy_out.dim() == 3:\n",
        "        dummy_feature = dummy_out[:,0]\n",
        "      else:\n",
        "        dummy_feature = dummy_out\n",
        "      feature_dim = dummy_feature.shape[1]\n",
        "      print(\"Detected feature dimontion:\", feature_dim)\n",
        "\n",
        "\n",
        "      #Difineing the classification Head\n",
        "      self.head = nn.Linear(feature_dim, num_classes)\n",
        "\n",
        "      #Ensure the head is trainable.\n",
        "      for param in self.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #pass the input through the backbone\n",
        "    features = self.backbone(x)\n",
        "\n",
        "    # If featers are retuened as (B, T, D), use the first token\n",
        "    if features.dim() == 3:\n",
        "      cls_token = features[:,0]\n",
        "    else:\n",
        "      cls_token = features\n",
        "    logits = self.head(cls_token)\n",
        "\n",
        "    return logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DinoClassifire(dino_model=dino_model, num_classes=100, device=device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJgLrg55Frn0",
        "outputId": "347a3b02-ab53-4cdf-b715-a51978bc8b2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected feature dimontion: 384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DinoClassifire(\n",
              "  (backbone): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "    (head): Identity()\n",
              "  )\n",
              "  (head): Linear(in_features=384, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config the loss, optimizer and training loop"
      ],
      "metadata": {
        "id": "st7g-B0cqz_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.head.parameters(),lr=1e-3)\n",
        "optimizer = optim.SGD(model.head.parameters(),lr=1e-3, momentum=0.9 )\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  message = \"\"\n",
        "  for index, (images, lables) in enumerate(train_loader):\n",
        "    images = images.to(device).requires_grad_(True)\n",
        "    lables =  lables.to(device)\n",
        "\n",
        "    if index % 10 == 0:\n",
        "      clear_output(wait=True)\n",
        "      print(f\"Epoch:{epoch+1}/{num_epochs}, Batch:{index+1}/{len(train_loader)}, {message}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,lables)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item() +images.size(0)\n",
        "\n",
        "  epoch_loss = running_loss / len(train_loader.dataset)\n",
        "  message = f\"Epoch:{epoch+1},Loss {epoch_loss:.4f}\"\n",
        "  print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ake2eua1qsS4",
        "outputId": "13e71416-5e49-4b63-8f1f-41876042d2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/10, Batch:51/782, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "JHjAUk5G1vyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eveluation(model, data_loader):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, lables in  data_loader:\n",
        "      images, lables = images.to(device), lables.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, prediction = torch.max(outputs.data,1)\n",
        "\n",
        "      total += lables.size(0)\n",
        "      correct += (prediction == lables).sum().item()\n",
        "    for i in range(len(prediction)):\n",
        "      print(prediction[i], lables[i])\n",
        "    return correct/ total\n",
        "\n",
        "test_accracy = eveluation(model, test_loader)\n",
        "print(f\"evaluation accurace:{test_accracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "x_OeEsgd14-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61dc07b-676a-47eb-9c04-3f7e91cd3911"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(59, device='cuda:0') tensor(96, device='cuda:0')\n",
            "tensor(90, device='cuda:0') tensor(90, device='cuda:0')\n",
            "tensor(77, device='cuda:0') tensor(14, device='cuda:0')\n",
            "tensor(77, device='cuda:0') tensor(77, device='cuda:0')\n",
            "tensor(4, device='cuda:0') tensor(65, device='cuda:0')\n",
            "tensor(7, device='cuda:0') tensor(7, device='cuda:0')\n",
            "tensor(75, device='cuda:0') tensor(75, device='cuda:0')\n",
            "tensor(27, device='cuda:0') tensor(27, device='cuda:0')\n",
            "tensor(16, device='cuda:0') tensor(16, device='cuda:0')\n",
            "tensor(30, device='cuda:0') tensor(30, device='cuda:0')\n",
            "tensor(74, device='cuda:0') tensor(50, device='cuda:0')\n",
            "tensor(83, device='cuda:0') tensor(83, device='cuda:0')\n",
            "tensor(63, device='cuda:0') tensor(14, device='cuda:0')\n",
            "tensor(51, device='cuda:0') tensor(51, device='cuda:0')\n",
            "tensor(42, device='cuda:0') tensor(42, device='cuda:0')\n",
            "tensor(70, device='cuda:0') tensor(70, device='cuda:0')\n",
            "evaluation accurace:0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "IEY_c43a89jk"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}