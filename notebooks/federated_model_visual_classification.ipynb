{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "fu0Iz0LDlRDK",
        "KqWviCIKs-eN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-rahbari/federated-learning_visual-classification/blob/mmd_branch/notebooks/federated_model_visual_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing DINO and installing its dependencies"
      ],
      "metadata": {
        "id": "fu0Iz0LDlRDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clon the DINO ripo\n",
        "!git clone https://github.com/facebookresearch/dino.git"
      ],
      "metadata": {
        "id": "IckKkLcG0zeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "07b26cdc-9dc1-4b17-e328-b714450ab026"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Total 175 (delta 0), reused 0 (delta 0), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (175/175), 24.47 MiB | 42.32 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Installing required dependencies regarding DINO\n",
        "%cd dino\n",
        "!pip install -r requirements.txt\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dY0yvkTfiNV3",
        "outputId": "3b8c9a47-d2ea-4734-a810-a8d5c2a8b6ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dino/dino\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# preprocessing the CIFAR-100 dataset\n",
        "\n",
        "feature size in CIFAR is 32x32 but DINO requires 224x224 in the input layer.\n",
        "\n",
        "In first step we upscale the dataset and then we add randomization to it\n",
        "\n",
        "In last step of transformation we normalize data usind mean value and standard division of ImageNet\n",
        "\n"
      ],
      "metadata": {
        "id": "M9hv0ik3jZ-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split,DataLoader"
      ],
      "metadata": {
        "id": "dDodXJD_lPCd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform_train = transforms.Compose([\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.RandomCrop(224),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "#                          std=(0.229, 0.224, 0.225))\n",
        "# ])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_4ydT67FmAQR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "from torchvision.datasets import CIFAR100\n",
        "# train_dataset = torchvision.datasets.CIFAR100(\n",
        "#     root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "#                                        download=True, transform=transform)\n",
        "\n",
        "\n",
        "# full_train = ConcatDataset([train_dataset, test_dataset])\n",
        "\n",
        "\n",
        "class ExtendedCIFAR100(CIFAR100):\n",
        "    def __init__(self, root, train=True, transform=None, download=False):\n",
        "        super().__init__(root=root, train=train, transform=transform, download=download)\n",
        "\n",
        "        # Load the test dataset\n",
        "        test_dataset = CIFAR100(root=root, train=False, download=download)\n",
        "\n",
        "        # Concatenate data using numpy\n",
        "        self.data = np.concatenate((self.data, test_dataset.data), axis=0)\n",
        "\n",
        "        # Concatenate targets using list concatenation\n",
        "        self.targets = self.targets + test_dataset.targets\n",
        "\n",
        "        self.indices = list(range(len(self.data)))\n",
        "\n",
        "full_train = ExtendedCIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "\n",
        "# Verify the length of the new dataset\n",
        "print(f\"Length of combined dataset: {len(full_train)}\")\n"
      ],
      "metadata": {
        "id": "CNgGMkqaqX-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267b4266-729d-41e9-9f4d-584884051151"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of combined dataset: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Subset\n",
        "import numpy as np\n",
        "import random\n",
        "import torch"
      ],
      "metadata": {
        "id": "dNQ67lu7cYNj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Hyperparameters regarding the data spliting here!\n",
        "\n",
        "\n",
        "# DO NOT FOREGET TO TEST K-FOLD SLPITTING !!!!!"
      ],
      "metadata": {
        "id": "t4oXrqMHwAit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title set the parameters here!!\n",
        "\n",
        "\n",
        "\n",
        "number_of_clients = None\n",
        "train_frac = 0.8 #@param\n",
        "val_frac = 0.2 #@param\n",
        "is_seed_fixed = True #@param{type:\"boolean\"}\n",
        "seed = 42 #@param{type:\"integer\"}\n",
        "\n",
        "def set_seed(seed=42, is_seed_fixed=True):\n",
        "  if not is_seed_fixed:\n",
        "    return\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seed(seed,is_seed_fixed)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown </br> <h5>Indicate the number of clients that contribute in training:</h5>\n",
        "n_clients = 10 #@param{type:\"integer\"}\n",
        "\n",
        "#@markdown </br></br> <b>splitting hyperparameters</b>\n",
        "\n",
        "spliting_method = \"non-i.i.d. sharing\" #@param[\"i.i.d. sharing\",\"non-i.i.d. sharing\"]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VJfqNlD_ORqk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set the parameters here only if <b>non-i.i.d. sharing</b> method had been selected!!\n",
        "#@markdown Nc is the number of classes that each subset can contain\n",
        "if spliting_method == \"non-i.i.d. sharing\":\n",
        "  Nc = 70 #@param{type:\"integer\"}\n",
        "\n",
        "  # are_classes_overlaping = False #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown <h3>If we consider the Number of classes M and nummber of client K then:</h3>\n",
        "#@markdown <ul>\n",
        "#@markdown   <li>Nc should be:\n",
        "#@markdown     <ul>\n",
        "#@markdown       <li>\n",
        "#@markdown         Greater than or equal to <b>\\\\(\\frac{M}{K}\\\\)</b>\n",
        "#@markdown       </li>\n",
        "#@markdown       <li>\n",
        "#@markdown         Less than or equal to K </b>\n",
        "#@markdown       </li>\n",
        "#@markdown     </ul>\n",
        "#@markdown   </li>\n",
        "#@markdown   <li>\n",
        "#@markdown   Muximum number of clients means all classes contribute in every client\n",
        "#@markdown   </li>\n",
        "\n",
        "#@markdown </ul>\n",
        "\n",
        "\n",
        "#@markdown </br></br><h3>Combination of classes are randomly selected which suits definition of federated learning especially Cross-device federated learning</h3>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W4gR7IvnxqL6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data splitting"
      ],
      "metadata": {
        "id": "bVtH-qLIrAeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title data splitting\n",
        "\n",
        "set_seed(seed,is_seed_fixed)\n",
        "generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "total_size = len(full_train)\n",
        "train_size = int(train_frac * total_size)\n",
        "val_size   = total_size - train_size\n",
        "\n",
        "train_set, val_set = random_split(full_train, [train_size, val_size], generator=generator)\n",
        "train_indices = torch.tensor(train_set.indices)\n",
        "val_indices = torch.tensor(val_set.indices)\n",
        "\n",
        "train_set = Subset(train_set.dataset, train_indices)\n",
        "val_set = Subset(val_set.dataset, val_set.indices)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=len(train_set), shuffle=False)\n",
        "val_loader  =  DataLoader(val_set, batch_size=len(val_set), shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Train dataset size: {len(train_set)}\")\n",
        "print(f\"Validation dataset size: {len(val_set)}\")\n",
        "\n",
        "lenghts = [train_size//n_clients] * n_clients\n",
        "\n",
        "for i in range(train_size % n_clients):\n",
        "  lenghts[i] += 1\n",
        "print(\"Size of subset: \", lenghts)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmFcWGtXrLS1",
        "outputId": "1b3c5675-5d98-44c8-faa0-7448c8c0be3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 48000\n",
            "Validation dataset size: 12000\n",
            "Size of subset:  [4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title i.i.d sharing - split data dased on number of clients and with respect of label proportionality\n",
        "set_seed(seed,is_seed_fixed)\n",
        "def iid_sharing(dataset, n_clients):\n",
        "\n",
        "  full_train_indices = dataset.indices\n",
        "  full_train_labels = torch.from_numpy(np.array(dataset .dataset.targets)[full_train_indices]) #collects labels from all dataset\n",
        "  unique_lables = torch.unique(full_train_labels) #Removes dupilication and generates a uniuqe list of labels (classes)\n",
        "  proportionality ={}\n",
        "  classes_indices = {}\n",
        "\n",
        "\n",
        "  for i in unique_lables:\n",
        "    proportionality[i] =( full_train_labels == i).sum() / len(full_train_labels) #Calculates proportinality of each class\n",
        "    classes_indices[i] = torch.nonzero(full_train_labels == i).squeeze() #Collects and save Indices in an array based on classes\n",
        "\n",
        "  for i in classes_indices.keys():\n",
        "    classes_indices[i] = classes_indices[i][torch.randperm(classes_indices[i].shape[0])] #suffels the indices\n",
        "\n",
        "  client_data_size = len(full_train_labels) / n_clients #Minimum dataset size of each client\n",
        "\n",
        "  client_indices = {}\n",
        "\n",
        "  #For each client we generate a element in client_indices dict to keep track of indices we'll associated with each client\n",
        "  for client in range(n_clients):\n",
        "    if not client_indices.get(client):\n",
        "      client_indices[client] = torch.empty(0, dtype=torch.long)\n",
        "  #__________________\n",
        "\n",
        "\n",
        "  #For each client we calculate how many samples from each specific label should be seperated. We take out the requried number of them form the list\n",
        "    for label in proportionality.keys():\n",
        "      pointer = proportionality[label] * client_data_size\n",
        "      pointer = int(pointer) if not pointer % 1 else int(pointer) + 1\n",
        "      pointer = min(pointer,classes_indices[label].size()[0])\n",
        "      pointer = pointer if pointer < classes_indices[label].size()[0] else classes_indices[label].size()[0]\n",
        "      client_indices[client] = torch.cat((client_indices[client], classes_indices[label][:pointer]), dim=0)\n",
        "      classes_indices[label] = classes_indices[label][pointer:]\n",
        "\n",
        "\n",
        "  #After spliting data we distribute remaining samples amoung the clients\n",
        "  for label in classes_indices.keys():\n",
        "    while True:\n",
        "      for client in client_indices.keys():\n",
        "\n",
        "        if classes_indices[label].size()[0] == 0:\n",
        "          break\n",
        "        client_indices[client] = torch.cat((\n",
        "            client_indices[client],\n",
        "            classes_indices[label][:1] ),\n",
        "            dim=0)\n",
        "\n",
        "\n",
        "        classes_indices[label] = classes_indices[label][1:]\n",
        "\n",
        "      if classes_indices[label].size()[0] == 0:\n",
        "        break\n",
        "\n",
        "\n",
        "  #spilt actual dataset to mulitiple subset for clients\n",
        "  client_data={\n",
        "      client_id: Subset(dataset.dataset,indices[torch.randperm(len(indices))])\n",
        "      for client_id, indices in client_indices.items()\n",
        "  }\n",
        "  return client_data\n",
        "\n",
        "\n",
        "indices_check = []\n",
        "client_data = iid_sharing(train_set, n_clients)\n",
        "for client_id in client_data.keys():\n",
        "  indices_check = indices_check + list(client_data[client_id].indices)\n",
        "  print(f\"Client {client_id} has {len(client_data[client_id])} samples\")\n",
        "\n"
      ],
      "metadata": {
        "id": "n86IvSfkp9Zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a09c3be-e7ed-4bfd-fe86-626856648711"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 has 4847 samples\n",
            "Client 1 has 4847 samples\n",
            "Client 2 has 4847 samples\n",
            "Client 3 has 4847 samples\n",
            "Client 4 has 4847 samples\n",
            "Client 5 has 4847 samples\n",
            "Client 6 has 4847 samples\n",
            "Client 7 has 4847 samples\n",
            "Client 8 has 4847 samples\n",
            "Client 9 has 4377 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Non i.i.d sharing\n",
        "\n",
        "\n",
        "# @title i.i.d sharing - split data dased on number of clients and with respect of label proportionality\n",
        "set_seed(seed,is_seed_fixed)\n",
        "def noniid_sharing(dataset,Nc , n_clients):\n",
        "\n",
        "  full_train_indices = dataset.indices\n",
        "  full_train_labels = torch.from_numpy(np.array(dataset .dataset.targets)[full_train_indices]) #collects labels from all dataset\n",
        "  unique_lables = torch.unique(full_train_labels) #Removes dupilication and generates a uniuqe list of labels (classes)\n",
        "\n",
        "  classes_indices = {}\n",
        "  classes_size = torch.zeros(unique_lables.size()[0])\n",
        "\n",
        "  class_combs = get_class_combinations(unique_lables, Nc, n_clients)\n",
        "\n",
        "  classes_num_partition = torch.zeros(unique_lables.size()[0])\n",
        "\n",
        "  for i in unique_lables:\n",
        "    classes_num_partition[i] = torch.sum(class_combs == i)\n",
        "    classes_indices[i.item()] = torch.nonzero(full_train_labels == i).squeeze() #Collects and save Indices in an array based on classe\n",
        "    classes_size[i] = classes_indices[i.item()].size()[0] #Calculate the number of smaples belonging to each class\n",
        "\n",
        "  for i in classes_indices.keys():\n",
        "    classes_indices[i] = classes_indices[i][torch.randperm(classes_indices[i].shape[0])] #suffels the indices\n",
        "\n",
        "  client_indices = {}\n",
        "\n",
        "  #For each client we generate a element in client_indices dict to keep track of indices we'll associated with each client\n",
        "\n",
        "  for client in range(n_clients):\n",
        "    client_indices[client] = torch.tensor([],dtype=torch.int16)\n",
        "    for cls in class_combs[client]:\n",
        "      cls = cls.item()\n",
        "\n",
        "      class_partition = torch.empty(0, dtype=torch.int64)\n",
        "\n",
        "      portion  = classes_size[cls] /classes_num_partition[cls]\n",
        "      portion = int(portion) if not portion % 1 else int(portion) + 1\n",
        "\n",
        "      if portion < classes_indices[cls].size()[0]:\n",
        "        class_partition = classes_indices[cls][:portion]\n",
        "        classes_indices[cls] = classes_indices[cls][portion:]\n",
        "      else:\n",
        "        class_partition = classes_indices[cls]\n",
        "        classes_indices[cls] = torch.tensor([])\n",
        "      client_indices[client] = torch.cat((client_indices[client], class_partition), dim=0)\n",
        "\n",
        "  client_data={\n",
        "      client_id: Subset(dataset.dataset,indices[torch.randperm(len(indices))])\n",
        "      for client_id, indices in client_indices.items()\n",
        "  }\n",
        "\n",
        "\n",
        "  check_list = {}\n",
        "\n",
        "  return client_data, class_combs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_class_combinations(classes, Nc, n_clients):\n",
        "\n",
        "  if Nc * n_clients < len(classes):\n",
        "    Nc = len(classes) / n_clients\n",
        "    Nc = int(Nc) if not Nc % 1 else int(Nc) + 1\n",
        "\n",
        "    print(f\"Number of classes per clients is lower then minimum. Nc changed to {Nc} (the least possible value)\")\n",
        "\n",
        "  combinations = torch.zeros((n_clients,Nc),dtype= torch.int64)\n",
        "  counter =0\n",
        "  ofset = 0\n",
        "  flag = False\n",
        "\n",
        "  for i in range(n_clients):\n",
        "    if not flag:\n",
        "      end_pointer = (i + 1) * Nc\n",
        "      if end_pointer >= classes.size()[0]:\n",
        "          ofset = (end_pointer - classes.size()[0])\n",
        "          flag = True\n",
        "\n",
        "      combinations[i] = classes[i* Nc - ofset: end_pointer - ofset]\n",
        "\n",
        "    else:\n",
        "\n",
        "      combinations[i]  = torch.randperm(classes.size()[0])[:Nc]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return combinations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "client_data, class_combs = noniid_sharing(train_set,5, 25)\n"
      ],
      "metadata": {
        "id": "UHYGEz82-ZJs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log System\n",
        "\n",
        "In this section Requerd Data will be archaved.<br/><br/>\n",
        "**Archaving this inforamtion will make it possible to:**\n",
        "*   Handel Clients\n",
        "*   Manage the models\n",
        "*   Keep track of results of different Backbones\n",
        "*   Compare measurement criteria\n",
        "*   Handel model merging process\n",
        "*   Save path to the models\n",
        "\n",
        "<br/><br/>\n",
        "**These data will be saved in two seperted csv file to :**\n",
        "\n",
        "1.   Archave the LOCAL Models  \n",
        "2.   Archave the GLOBAL Models resulted by each round\n",
        "\n",
        "<br/><br/>\n",
        "The csv files will be handeled as panda.dataframe and each row in the csv file addresses one of models\n",
        "<br/>\n",
        "\n",
        "**Columns (COMMON):**<br/>\n",
        "1. Backbone model name\n",
        "2. Model name\n",
        "3. Path\n",
        "4. Time of log\n",
        "5. Measurement criteria\n",
        " * loss\n",
        " * Accuracy\n",
        " * ...?\n",
        "6. Size of dataset\n",
        "\n",
        "**Columns (Local Models only):**<br/>\n",
        "7. Client Id\n",
        "8. Classes (Indicate which classes have been covered by each client)(format:\"2,4,63,80,9\" or \"all\" for all the classes)\n",
        "9. Round number\n",
        "10. Duration of training\n",
        "11. Train Test ratio\n",
        "\n",
        "**Columns (Global Models only):**<br/>\n",
        "7. Number of clients\n",
        "7. Number of rounds\n",
        "8. Model Aggregation method\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KqWviCIKs-eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Functions\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "def get_current_time():\n",
        "  now = datetime.now()\n",
        "\n",
        "  formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\") # Format the date and time as a string\n",
        "\n",
        "  return formatted_date_time\n",
        "\n",
        "\n",
        "\n",
        "tic_start_time = None\n",
        "\n",
        "def tic():\n",
        "    global tic_start_time\n",
        "    tic_start_time = time.perf_counter() # start the timer\n",
        "\n",
        "def toc():\n",
        "    if tic_start_time is None:\n",
        "        print(\"Error: You must call tic() before toc()\")\n",
        "        return None\n",
        "    elapsed_time = time.perf_counter() - tic_start_time\n",
        "    return elapsed_time\n",
        "\n",
        "\n",
        "def load_storage():\n",
        "  drive.mount('/content/drive')\n",
        "  path_to_clients = '/content/drive/MyDrive/MLDL_FederatedLearning/models/clients/'\n",
        "  path_to_global  = '/content/drive/MyDrive/MLDL_FederatedLearning/models/global/'\n",
        "  return path_to_clients, path_to_global\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_client(model,client,round_number,backbone,path_to_clients):\n",
        "  round_number = str(round_number)\n",
        "  round_number = \"0\"*(4-len(round_number)) + round_number\n",
        "\n",
        "  client = str(client)\n",
        "  client = \"0\"*(4-len(client)) + client\n",
        "\n",
        "  model_name = backbone + \"_\" + client + \"_\" + round_number + \".pth\"\n",
        "\n",
        "  path =  path_to_clients + model_name\n",
        "\n",
        "  numbertorch.save(model.state_dict(),  path )\n",
        "\n",
        "  return model_name, path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_global_model(model,number_of_clients,number_of_round,backbone,path_to_global):\n",
        "  number_of_round = str(number_of_round)\n",
        "  number_of_round = \"0\"*(4-len(number_of_round)) + number_of_round\n",
        "\n",
        "  number_of_clients = str(number_of_clients)\n",
        "  number_of_clients = \"0\"*(4-len(number_of_clients)) + number_of_clients\n",
        "\n",
        "  model_name = backbone + \"_\" + number_of_clients + \"_\" + number_of_round + \".pth\"\n",
        "\n",
        "  path =  path_to_global + model_name\n",
        "\n",
        "  numbertorch.save(model.state_dict(), path  )\n",
        "\n",
        "  return model_name, path\n"
      ],
      "metadata": {
        "id": "CasHI07Ps4A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-3iedjvSi4Gm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}